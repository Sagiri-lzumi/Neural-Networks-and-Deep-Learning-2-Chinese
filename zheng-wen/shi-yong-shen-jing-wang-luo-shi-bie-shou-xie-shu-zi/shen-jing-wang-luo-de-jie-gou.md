---
description: The architecture of neural networks
---

# 神经网络的结构

在下一节中，我将介绍一个神经网络，它可以很好地对手写数字进行分类。在准备过程中，我们需要解释一些术语，以便为网络的不同部分命名。假设我们有这样一个网络；

<figure><img src="../../.gitbook/assets/image.png" alt=""><figcaption></figcaption></figure>

如前所述，该网络最左侧的层称为输入层，层内的神经元称为输入神经元。最右侧或输出层包含输出神经元，或者像本例中这样，包含单个输出神经元。中间一层称为隐藏层，因为这一层中的神经元既不是输入也不是输出。隐藏 “一词听起来可能有点神秘--我第一次听到这个词时，还以为它一定有什么深奥的哲学或数学含义--但它的真正含义不过是 ”既不是输入也不是输出"。上面的网络只有一个隐藏层，但有些网络有多个隐藏层。例如，下面的四层网络就有两个隐藏层：

<figure><img src="../../.gitbook/assets/image (1).png" alt=""><figcaption></figcaption></figure>

有些时候，出于历史原因，这类多层网络被称为**多层感知机**（Multilayer Perceptrons，简称MLPs），尽管它们实际上是由**S形神经元**（Sigmoid Neurons）组成的，而非感知机（Perceptrons）。在本书中，我不会使用“MLP”这个术语，因为我认为它可能会引起混淆，但我想在这里提醒你注意其存在。

输入层和输出层的设计通常是直接了当的。例如，假设我们正在尝试判断一张手写图像是否表示数字“9”。一种自然的网络设计方法是将图像像素的强度值编码到输入神经元中。

如果图像是**64×64的灰度图像**，我们将有 4,096=64×644,096 = 64 \times 644,096=64×64 个输入神经元，其像素强度值被适当地缩放到0到1之间。输出层将仅包含一个神经元，其输出值小于0.5时表示“输入图像不是数字9”，而输出值大于0.5时表示“输入图像是数字9”。

神经网络输入层和输出层的设计通常比较简单，但隐藏层的设计却很有艺术性。特别是，我们无法用几条简单的经验法则来概括隐藏层的设计过程。相反，神经网络研究人员为隐藏层开发了许多设计启发式方法，帮助人们从网络中获得他们想要的行为。

例如，这些启发式方法可以用来帮助确定如何权衡隐藏层的数量和训练网络所需的时间。我们将在本书的后面介绍几种这样的启发式设计方法。 到目前为止，我们一直在讨论将一层输出作为下一层输入的神经网络。这种网络被称为前馈神经网络。这意味着网络中没有循环--信息总是向前反馈，而不是向后反馈。如果有循环，我们就会出现 σ 的输入取决于输出的情况。 函数的输入取决于输出。这就很难理解了，所以我们不允许这种循环。 不过，也有其他人工神经网络模型可以实现反馈回路。这些模型被称为递归神经网络。

这些模型的理念是让神经元在一定时间内发射信号，然后进入静止状态。这种发射可以刺激其他神经元，这些神经元可能会在稍后发射，发射时间也是有限的。这将导致更多的神经元发射，于是随着时间的推移，我们就会得到一个神经元发射的级联。在这样的模型中，循环不会造成问题，因为神经元的输出只会在稍后的某个时间影响其输入，而不是瞬间影响。 递归神经网络的影响力不如前馈网络，部分原因是递归网络的学习算法（至少到目前为止）不那么强大。但递归网络仍然非常有趣。与前馈网络相比，它们在精神上更接近我们大脑的工作方式。而且，递归网络有可能解决前馈网络难以解决的重要问题。不过，为了限制我们的研究范围，在本书中，我们将专注于使用更为广泛的前馈网络。

